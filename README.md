# MultiModal-Reading-List
Reading List of Multi-Modal tasks.


### Contents

- [1. Multimodal-Sentiment-Analysis](#1-msa)
  - [1.1 Paper](#11-paper)
  - [1.2 Datasets](#12-datasets)
  
- [2. Multimodal-Aspect-based-Sentiment-Analysis](#2-mabsa)
  - [2.1 Paper](#21-paper)
  - [2.2 Datasets](#22-datasets)

- [3. Multimodal-Targeted-Sentiment-Analysis](#3-mtsc)
  - [3.1 Paper](#11-paper)
  - [3.2 Datasets](#12-datasets)
  
- [4. Multimodal-Sarcasm-Detection](#4-msd)
  - [4.1 Paper](#31-paper)
  - [4.2 Datasets](#32-datasets)
 
- [5. Multimodal-Emotion-Recognition](#5-mer)
  - [5.1 Paper](#41-paper)
  - [5.2 Datasets](#42-datasets)

- [6. Multimodal-Complaint-Identification](#6-mci)
  - [6.1 Paper](#51-paper)
  - [6.2 Datasets](#52-datasets)

- [7. Multimodal-Rumor-Detection](#7-mrd)
  - [7.1 Paper](#51-paper)
  - [7.2 Datasets](#52-datasets)

- [7. Others](#7-others)
  - [6.1 Paper](#61-paper)
  - [6.2 Datasets](#62-datasets)

<!--
  - [1.2 Aspect Extraction](#12-aspect-extraction)
  - [1.3 Opinion Extraction](#13-opinion-extraction)
  - [1.4 Category Detection](#14-category-detection)
  - [1.5 Aspect-Opinion Co-Extraction](#15-aspect-opinion-co-extraction)
  - [1.6 Aspect-Oriented Opinion Extraction](#16-aspect-oriented-opinion-extraction)
  - [1.7 Aspect-Opinion Pair Extraction](#17-aspect-opinion-pair-extraction)
  - [1.8 Aspect-Sentiment Pair Extraction](#18-aspect-sentiment-pair-extraction)
  - [1.9 Category-Oriented Sentiment Classification](#19-category-oriented-sentiment-classification)
  - [1.10 Category-Sentiment Hierarchical Classification](#110-category-sentiment-hierarchical-classification)
  - [1.11 Aspect-Category-Sentiment Triple Extraction](#111-aspect-category-sentiment-triple-extraction)
  - [1.12 Aspect-Opinion-Sentiment Triple Extraction](#112-aspect-opinion-sentiment-triple-extraction)
  - [1.13 Aspect-Category-Opinion-Sentiment Quadruple Extraction](#113-aspect-category-opinion-sentiment-quadruple-extraction)
- [2. Cross-Domain ABSA](#2-cross-domain-absa)
  - [2.1 Cross-Domain Aspect Extraction](#21-cross-domain-aspect-extraction)
  - [2.2 Cross-Domain Aspect-Opinion Co-Extraction](#22-cross-domain-aspect-opinion-co-extraction)
  - [2.3 Cross-Domain Aspect-Oriented Sentiment Classification](#23-cross-domain-aspect-oriented-sentiment-classification)
  - [2.4 Cross-Domain Aspect-Sentiment Pair Extraction](#24-cross-domain-aspect-sentiment-pair-extraction)
- [3. Multi-Modal ABSA](#3-multi-modal-absa)
  - [3.1 Multi-Modal Aspect Extraction (& Multi-Modal Named Entity Recognition)](#31-multi-modal-aspect-extraction--multi-modal-named-entity-recognition)
  - [3.2 Multi-Modal Category-Oriented Sentiment Classification](#32-multi-modal-category-oriented-sentiment-classification)
  - [3.3 Multi-Modal Aspect-Oriented Sentiment Classification](#33-multi-modal-aspect-oriented-sentiment-classification)
  - [3.4 Multi-Modal Aspect-Sentiment Pair Extraction](#34-multi-modal-aspect-sentiment-pair-extraction)
-->

## 1. Multimodal-Sentiment-Analysis
### 1.1 paper
1. Yang Wu, Yanyan Zhao, Hao Yang, Song Chen, Bing Qin, Xiaohuan Cao, Wenting Zhao. **Sentiment Word Aware Multimodal Refinement for Multimodal Sentiment Analysis with ASR Errors**. ACL findings 2022. [[paper]](https://aclanthology.org/2022.findings-acl.109/) [[code]](https://github.com/albertwy/SWRM)

1. Devamanyu Hazarika, Yingting Li, Bo Cheng, Shuai Zhao, Roger Zimmermann, Soujanya Poria. **Analyzing Modality Robustness in Multimodal Sentiment Analysis**. NAACL short 2022. [[paper]](https://arxiv.org/abs/2205.15465) [[code]](https://github.com/declare-lab/MSA-Robustness)

1. Zhen Li, Bing Xu, Conghui Zhu, Tiejun Zhao. **CLMLF: A Contrastive Learning and Multi-Layer Fusion Method for Multimodal Sentiment Detection**. NAACL findings 2022. [[paper]](https://arxiv.org/abs/2204.05515) [[code]](https://github.com/Link-Li/CLMLF)

### 1.2 datasets


## 2. Multimodal-Aspect-based-Sentiment-Analysis
### 2.1 paper
1. Yan Ling, Jianfei Yu, Rui Xia. **Vision-Language Pre-Training for Multimodal Aspect-Based Sentiment Analysis**. ACL 2022. [[paper]](https://aclanthology.org/2022.acl-long.152/) [[code]](https://github.com/NUSTM/VLP-MABSA)
 
### 2.2 datasets


## 3. Multimodal-Targeted-Sentiment-Analysis
### 3.1 paper
1. Jianfei Yu, Jieming Wang, Rui Xia, Junjie Li. **Targeted Multimodal Sentiment Classification based on Coarse-to-Fine Grained Image-Target Matching**. IJCAI 2022. 


### 3.2 datasets


## 4. Multimodal-Sarcasm-Detection
### 4.1 paper
1. Bin Liang, Chenwei Lou, Xiang Li, Min Yang, Lin Gui, Yulan He, Wenjie Pei, Ruifeng Xu. **Multi-Modal Sarcasm Detection via Cross-Modal Graph Convolutional Network**. ACL 2022. [[paper]](https://aclanthology.org/2022.acl-long.124/) [[code]](https://github.com/HITSZ-HLT/CMGCN)
 
### 4.2 datasets



## 5. Multimodal-Emotion-Recognition
### 5.1 paper
1. Yi Zhang, Mingyuan Chen, Jundong Shen, Chongjun Wang. **Tailor Versatile Multi-modal Learning for Multi-label Emotion Recognition**. AAAI 2022. [[paper]](https://arxiv.org/pdf/2201.05834.pdf) [[code]](https://github.com/kniter1/TAILOR)
 
### 5.2 datasets


## 6. Multimodal-Complaint-Identification
### 6.1 paper
1. Apoorva Singh, Soumyodeep Dey, Anamitra Singha, Sriparna Saha. **Sentiment and Emotion-aware Multi-modal Complaint Identification**. AAAI 2022. [[paper]](https://www.aaai.org/AAAI22Papers/AISI-12009.SinghA.pdf)

### 6.2 datasets

## 7. Multimodal-Rumor-Detection
### 7.1 paper
1. Jiaqi Zheng, Xi Zhang, Sanchuan Guo, Quan Wang, Wenyu Zang, Yongdong Zhang. **MFAN: Multi-modal Feature-enhanced Attention Networks for Rumor Detection**. IJCAI 2022.

### 7.2 datasets


## 7. Others
### 7.1 paper

### 7.2 datasets
1. 【Depression Detection】J Yoon, C Kang, S Kim, J Han. **D-Vlog: Multimodal Vlog Dataset for Depression Detection**. AAAI 2022. [[paper]](https://www.aaai.org/AAAI22Papers/AISI-6612.YoonJ.pdf)

