# MultiModal-Reading-List
Reading List of Multi-Modal tasks.


### Contents

- [1. Multimodal-Sentiment-Analysis](#1-msa)
  - [1.1 Paper](#11-paper)
  - [1.2 Datasets](#12-datasets)
  
- [2. Multimodal-Aspect-based-Sentiment-Analysis](#2-mabsa)
  - [2.1 Paper](#21-paper)
  - [2.2 Datasets](#22-datasets)
  
- [3. Multimodal-Sarcasm Detection](#2-msd)
  - [3.1 Paper](#31-paper)
  - [3.2 Datasets](#32-datasets)

<!--
  - [1.2 Aspect Extraction](#12-aspect-extraction)
  - [1.3 Opinion Extraction](#13-opinion-extraction)
  - [1.4 Category Detection](#14-category-detection)
  - [1.5 Aspect-Opinion Co-Extraction](#15-aspect-opinion-co-extraction)
  - [1.6 Aspect-Oriented Opinion Extraction](#16-aspect-oriented-opinion-extraction)
  - [1.7 Aspect-Opinion Pair Extraction](#17-aspect-opinion-pair-extraction)
  - [1.8 Aspect-Sentiment Pair Extraction](#18-aspect-sentiment-pair-extraction)
  - [1.9 Category-Oriented Sentiment Classification](#19-category-oriented-sentiment-classification)
  - [1.10 Category-Sentiment Hierarchical Classification](#110-category-sentiment-hierarchical-classification)
  - [1.11 Aspect-Category-Sentiment Triple Extraction](#111-aspect-category-sentiment-triple-extraction)
  - [1.12 Aspect-Opinion-Sentiment Triple Extraction](#112-aspect-opinion-sentiment-triple-extraction)
  - [1.13 Aspect-Category-Opinion-Sentiment Quadruple Extraction](#113-aspect-category-opinion-sentiment-quadruple-extraction)
- [2. Cross-Domain ABSA](#2-cross-domain-absa)
  - [2.1 Cross-Domain Aspect Extraction](#21-cross-domain-aspect-extraction)
  - [2.2 Cross-Domain Aspect-Opinion Co-Extraction](#22-cross-domain-aspect-opinion-co-extraction)
  - [2.3 Cross-Domain Aspect-Oriented Sentiment Classification](#23-cross-domain-aspect-oriented-sentiment-classification)
  - [2.4 Cross-Domain Aspect-Sentiment Pair Extraction](#24-cross-domain-aspect-sentiment-pair-extraction)
- [3. Multi-Modal ABSA](#3-multi-modal-absa)
  - [3.1 Multi-Modal Aspect Extraction (& Multi-Modal Named Entity Recognition)](#31-multi-modal-aspect-extraction--multi-modal-named-entity-recognition)
  - [3.2 Multi-Modal Category-Oriented Sentiment Classification](#32-multi-modal-category-oriented-sentiment-classification)
  - [3.3 Multi-Modal Aspect-Oriented Sentiment Classification](#33-multi-modal-aspect-oriented-sentiment-classification)
  - [3.4 Multi-Modal Aspect-Sentiment Pair Extraction](#34-multi-modal-aspect-sentiment-pair-extraction)
-->

## 1. Multimodal-Sentiment-Analysis
### 1.1 paper
1. Bo Wang, Tao Shen, Guodong Long, Tianyi Zhou, Yi Chang. **Sentiment Word Aware Multimodal Refinement for Multimodal Sentiment Analysis with ASR Errors**. ACL 2022. [[paper]](https://aclanthology.org/2022.findings-acl.109/) [[code]](https://github.com/albertwy/SWRM)
 
### 1.2 datasets


## 2. Multimodal-Aspect-based-Sentiment-Analysis
### 2.1 paper
1. Yan Ling, Jianfei Yu, Rui Xia. **Vision-Language Pre-Training for Multimodal Aspect-Based Sentiment Analysis**. ACL 2022. [[paper]](https://aclanthology.org/2022.acl-long.152/) [[code]](https://github.com/NUSTM/VLP-MABSA)
 
### 2.2 datasets


## 3. Multimodal-Sarcasm-Detection
### 3.1 paper
1. Bin Liang, Chenwei Lou, Xiang Li, Min Yang, Lin Gui, Yulan He, Wenjie Pei, Ruifeng Xu. **Multi-Modal Sarcasm Detection via Cross-Modal Graph Convolutional Network**. ACL 2022. [[paper]](https://aclanthology.org/2022.acl-long.124/) [[code]](https://github.com/HITSZ-HLT/CMGCN)
 
### 3.2 datasets


